{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "dict_keys(['CTRES', 'ANA', 'SUV', 'SEG', 'INTERPOLATED_ANA', 'CONCAT'])\n"
     ]
    }
   ],
   "source": [
    "# COMMAND: pthon -m data.loader +LOADER=local\n",
    "DS_PATH = \"/Users/keyi/Desktop/ds_11_06/preprocessed_data_1_val.pt\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "ds = torch.load(DS_PATH, weights_only=False)\n",
    "\n",
    "# only focus on the first batch now\n",
    "# print(ds[0])\n",
    "print(len(ds[0]))\n",
    "print(ds[0].keys())\n",
    "\n",
    "### 2.7G for only 2 samples!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but we actually only need the CONCAT and label (either SEG or  INTERPOLATED ANA)so we can just filter them out to avoid OOM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "dict_keys(['CONCAT', 'SEG'])\n",
      "torch.Size([3, 399, 399, 326])\n",
      "torch.Size([1, 399, 399, 326])\n"
     ]
    }
   ],
   "source": [
    "DS_PATH = \"/Users/keyi/Desktop/ds_11_06_modified/preprocessed_data_1_val.pt\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "ds = torch.load(DS_PATH, weights_only=False)\n",
    "\n",
    "# only focus on the first batch now\n",
    "# print(ds[0])\n",
    "print(len(ds[0]))\n",
    "print(ds[0].keys())\n",
    "\n",
    "## 1.5G for 2 samples now -> CONCAT + SEG\n",
    "print(ds[0]['CONCAT'].shape)\n",
    "print(ds[0]['SEG'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "dict_keys(['CONCAT', 'INTERPOLATED_ANA'])\n",
      "torch.Size([2, 250, 250, 326])\n",
      "torch.Size([1, 250, 250, 326])\n"
     ]
    }
   ],
   "source": [
    "### MULTI-LABEL SEGMENTATION\n",
    "DS_PATH = \"/Users/keyi/Desktop/ds_11_06_multilabel/preprocessed_data_1_val.pt\"\n",
    "\n",
    "ds = torch.load(DS_PATH, weights_only=False)\n",
    "\n",
    "# only focus on the first batch now\n",
    "# print(ds[0])\n",
    "print(len(ds[0]))\n",
    "print(ds[0].keys())\n",
    "\n",
    "## 600mb for 2 samples now -> CONCAT + INTERPOLATED ANA\n",
    "print(ds[0]['CONCAT'].shape)\n",
    "print(ds[0]['INTERPOLATED_ANA'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n",
      "dict_keys(['CONCAT', 'SEG'])\n",
      "torch.Size([3, 96, 96, 96])\n",
      "torch.Size([1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATASET\n",
    "DS_PATH = \"/Users/keyi/Desktop/ds_11_07_train/preprocessed_data_1_train.pt\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "ds = torch.load(DS_PATH, weights_only=False)\n",
    "\n",
    "print(len(ds)) # 6 samples\n",
    "# only focus on the first batch now\n",
    "# print(ds[0])\n",
    "print(len(ds[0])) # each sample has 2 patches\n",
    "\n",
    "print(ds[0][0].keys())\n",
    "print(ds[0][0]['CONCAT'].shape)\n",
    "print(ds[0][0]['SEG'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "dict_keys(['CONCAT', 'SEG'])\n",
      "torch.Size([3, 250, 250, 204])\n",
      "torch.Size([1, 250, 250, 204])\n",
      "metatensor([[[[-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          ...,\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565]],\n",
      "\n",
      "         [[-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          ...,\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565]],\n",
      "\n",
      "         [[-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          ...,\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          ...,\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565]],\n",
      "\n",
      "         [[-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          ...,\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565]],\n",
      "\n",
      "         [[-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          ...,\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565],\n",
      "          [-5.9565, -5.9565, -5.9565,  ..., -5.9565, -5.9565, -5.9565]]],\n",
      "\n",
      "\n",
      "        [[[-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          ...,\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676]],\n",
      "\n",
      "         [[-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          ...,\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676]],\n",
      "\n",
      "         [[-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          ...,\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          ...,\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676]],\n",
      "\n",
      "         [[-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          ...,\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676]],\n",
      "\n",
      "         [[-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          ...,\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676],\n",
      "          [-5.4676, -5.4676, -5.4676,  ..., -5.4676, -5.4676, -5.4676]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          ...,\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017]],\n",
      "\n",
      "         [[ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          ...,\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017]],\n",
      "\n",
      "         [[ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          ...,\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          ...,\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017]],\n",
      "\n",
      "         [[ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          ...,\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017]],\n",
      "\n",
      "         [[ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          ...,\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017],\n",
      "          [ 0.5017,  0.5017,  0.5017,  ...,  0.5017,  0.5017,  0.5017]]]])\n",
      "torch.Size([3, 250, 250, 204])\n",
      "torch.Size([1, 250, 250, 204])\n"
     ]
    }
   ],
   "source": [
    "### MULTI-LABEL SEGMENTATION\n",
    "import torch\n",
    "DS_PATH = \"/Users/keyi/Desktop/ds_11_16_multilabel/preprocessed_data_1_val.pt\"\n",
    "\n",
    "ds = torch.load(DS_PATH, weights_only=False)\n",
    "\n",
    "# only focus on the first batch now\n",
    "# print(ds[0])\n",
    "print(len(ds[0]))\n",
    "print(ds[0].keys())\n",
    "\n",
    "## 600mb for 2 samples now -> CONCAT + INTERPOLATED ANA\n",
    "print(ds[0]['CONCAT'].shape)\n",
    "print(ds[0]['SEG'].shape)\n",
    "print(ds[0][\"CONCAT\"])\n",
    "print(ds[1]['CONCAT'].shape)\n",
    "print(ds[1]['SEG'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "dict_keys(['CONCAT', 'INTERPOLATED_ANA'])\n",
      "torch.Size([2, 250, 250, 204])\n",
      "torch.Size([1, 250, 250, 204])\n",
      "torch.Size([2, 250, 250, 204])\n",
      "torch.Size([1, 250, 250, 204])\n"
     ]
    }
   ],
   "source": [
    "### MULTI-LABEL SEGMENTATION\n",
    "import torch\n",
    "DS_PATH = \"/Users/keyi/Desktop/ds_11_16_multilabel_2tries/preprocessed_data_1_val.pt\"\n",
    "\n",
    "ds = torch.load(DS_PATH, weights_only=False)\n",
    "\n",
    "# only focus on the first batch now\n",
    "# print(ds[0])\n",
    "print(len(ds[0]))\n",
    "print(ds[0].keys())\n",
    "\n",
    "## 389mb for 2 samples now -> CONCAT + INTERPOLATED ANA!!!\n",
    "print(ds[0]['CONCAT'].shape)\n",
    "print(ds[0]['INTERPOLATED_ANA'].shape)\n",
    "\n",
    "\n",
    "print(ds[1]['CONCAT'].shape)\n",
    "print(ds[1]['INTERPOLATED_ANA'].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvhci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
