{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernels_strides():\n",
    "    \"\"\"\n",
    "    This function is only used for decathlon datasets with the provided patch sizes.\n",
    "    When refering this method for other tasks, please ensure that the patch size for each spatial dimension should\n",
    "    be divisible by the product of all strides in the corresponding dimension.\n",
    "    In addition, the minimal spatial size should have at least one dimension that has twice the size of\n",
    "    the product of all strides. For patch sizes that cannot find suitable strides, an error will be raised.\n",
    "    \"\"\"\n",
    "    sizes, spacings = [96,96,96], [1.0, 1.0, 2.5]\n",
    "    input_size = sizes\n",
    "    strides, kernels = [], []\n",
    "    while True:\n",
    "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
    "        stride = [2 if ratio <= 2 and size >= 8 else 1 for (ratio, size) in zip(spacing_ratio, sizes)]\n",
    "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "        if all(s == 1 for s in stride):\n",
    "            break\n",
    "        for idx, (i, j) in enumerate(zip(sizes, stride)):\n",
    "            if i % j != 0:\n",
    "                raise ValueError(\n",
    "                    f\"Patch size is not supported, please try to modify the size {input_size[idx]} in the spatial dimension {idx}.\"\n",
    "                )\n",
    "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "        kernels.append(kernel)\n",
    "        strides.append(stride)\n",
    "\n",
    "    strides.insert(0, len(spacings) * [1])\n",
    "    kernels.append(len(spacings) * [3])\n",
    "    return kernels, strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (model): Sequential(\n",
       "    (0): Convolution(\n",
       "      (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (D): Dropout(p=0.0, inplace=False)\n",
       "        (A): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (1): SkipConnection(\n",
       "      (submodule): Sequential(\n",
       "        (0): Convolution(\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (D): Dropout(p=0.0, inplace=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "        (1): SkipConnection(\n",
       "          (submodule): Sequential(\n",
       "            (0): Convolution(\n",
       "              (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "              (adn): ADN(\n",
       "                (N): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (D): Dropout(p=0.0, inplace=False)\n",
       "                (A): PReLU(num_parameters=1)\n",
       "              )\n",
       "            )\n",
       "            (1): SkipConnection(\n",
       "              (submodule): Sequential(\n",
       "                (0): Convolution(\n",
       "                  (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "                  (adn): ADN(\n",
       "                    (N): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                    (D): Dropout(p=0.0, inplace=False)\n",
       "                    (A): PReLU(num_parameters=1)\n",
       "                  )\n",
       "                )\n",
       "                (1): SkipConnection(\n",
       "                  (submodule): Sequential(\n",
       "                    (0): Convolution(\n",
       "                      (conv): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "                      (adn): ADN(\n",
       "                        (N): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                        (D): Dropout(p=0.0, inplace=False)\n",
       "                        (A): PReLU(num_parameters=1)\n",
       "                      )\n",
       "                    )\n",
       "                    (1): SkipConnection(\n",
       "                      (submodule): Convolution(\n",
       "                        (conv): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                        (adn): ADN(\n",
       "                          (N): InstanceNorm3d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                          (D): Dropout(p=0.0, inplace=False)\n",
       "                          (A): PReLU(num_parameters=1)\n",
       "                        )\n",
       "                      )\n",
       "                    )\n",
       "                    (2): Convolution(\n",
       "                      (conv): ConvTranspose3d(1536, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "                      (adn): ADN(\n",
       "                        (N): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                        (D): Dropout(p=0.0, inplace=False)\n",
       "                        (A): PReLU(num_parameters=1)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (2): Convolution(\n",
       "                  (conv): ConvTranspose3d(512, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "                  (adn): ADN(\n",
       "                    (N): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                    (D): Dropout(p=0.0, inplace=False)\n",
       "                    (A): PReLU(num_parameters=1)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): Convolution(\n",
       "              (conv): ConvTranspose3d(256, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "              (adn): ADN(\n",
       "                (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "                (D): Dropout(p=0.0, inplace=False)\n",
       "                (A): PReLU(num_parameters=1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Convolution(\n",
       "          (conv): ConvTranspose3d(128, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "          (adn): ADN(\n",
       "            (N): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (D): Dropout(p=0.0, inplace=False)\n",
       "            (A): PReLU(num_parameters=1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Convolution(\n",
       "      (conv): ConvTranspose3d(64, 145, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from monai.networks.nets import DynUNet, UNet\n",
    "from omegaconf import DictConfig\n",
    "from loguru import logger\n",
    "class Monai_DynUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    DynUNet with registry\n",
    "    This is a prototype implementation of a DynUnet model.\n",
    "\n",
    "    Examples::\n",
    "        from config import cfg\n",
    "        from utils.registry import MODEL\n",
    "\n",
    "        model = MODEL['DynUnet'](cfg=cfg)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # MODEL misc\n",
    "        in_channels = 2    \n",
    "        spatial_dims = 3\n",
    "        out_channels = 2\n",
    "        \n",
    "       \n",
    "\n",
    "        # Define model\n",
    "        self.model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            channels=(32,64,128,256,512,1024),\n",
    "            out_channels=145,\n",
    "            #kernel_size=kernels,\n",
    "            strides=(2,2,2,2,2),\n",
    "            #400->200->100->50->25\n",
    "            norm=\"instance\",\n",
    "        )\n",
    "        self._out_channels = out_channels\n",
    "\n",
    "    @property\n",
    "    def out_channels(self):\n",
    "        \"\"\"Return the output channels of the model.\"\"\"\n",
    "        return self._out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "m = Monai_DynUNet()\n",
    "m.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-17 15:52:28.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mLoading pretrained anatomy model from /Users/keyi/Desktop/epoch=399-step=30460.ckpt\u001b[0m\n",
      "/var/folders/jw/3gmq54sn6q3cnlvsjqly5twr0000gn/T/ipykernel_76522/684356271.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(anatomy_ckpt_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint keys: odict_keys(['model.model.0.conv.weight', 'model.model.0.conv.bias', 'model.model.0.adn.A.weight', 'model.model.1.submodule.0.conv.weight', 'model.model.1.submodule.0.conv.bias', 'model.model.1.submodule.0.adn.A.weight', 'model.model.1.submodule.1.submodule.0.conv.weight', 'model.model.1.submodule.1.submodule.0.conv.bias', 'model.model.1.submodule.1.submodule.0.adn.A.weight', 'model.model.1.submodule.1.submodule.1.submodule.0.conv.weight', 'model.model.1.submodule.1.submodule.1.submodule.0.conv.bias', 'model.model.1.submodule.1.submodule.1.submodule.0.adn.A.weight', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.weight', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.bias', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.0.adn.A.weight', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.weight', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.bias', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.adn.A.weight', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.weight', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.bias', 'model.model.1.submodule.1.submodule.1.submodule.1.submodule.2.adn.A.weight', 'model.model.1.submodule.1.submodule.1.submodule.2.conv.weight', 'model.model.1.submodule.1.submodule.1.submodule.2.conv.bias', 'model.model.1.submodule.1.submodule.1.submodule.2.adn.A.weight', 'model.model.1.submodule.1.submodule.2.conv.weight', 'model.model.1.submodule.1.submodule.2.conv.bias', 'model.model.1.submodule.1.submodule.2.adn.A.weight', 'model.model.1.submodule.2.conv.weight', 'model.model.1.submodule.2.conv.bias', 'model.model.1.submodule.2.adn.A.weight', 'model.model.2.conv.weight', 'model.model.2.conv.bias', 'loss.dice.class_weight'])\n",
      "model keys: odict_keys(['model.0.conv.weight', 'model.0.conv.bias', 'model.0.adn.A.weight', 'model.1.submodule.0.conv.weight', 'model.1.submodule.0.conv.bias', 'model.1.submodule.0.adn.A.weight', 'model.1.submodule.1.submodule.0.conv.weight', 'model.1.submodule.1.submodule.0.conv.bias', 'model.1.submodule.1.submodule.0.adn.A.weight', 'model.1.submodule.1.submodule.1.submodule.0.conv.weight', 'model.1.submodule.1.submodule.1.submodule.0.conv.bias', 'model.1.submodule.1.submodule.1.submodule.0.adn.A.weight', 'model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.weight', 'model.1.submodule.1.submodule.1.submodule.1.submodule.0.conv.bias', 'model.1.submodule.1.submodule.1.submodule.1.submodule.0.adn.A.weight', 'model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.weight', 'model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.conv.bias', 'model.1.submodule.1.submodule.1.submodule.1.submodule.1.submodule.adn.A.weight', 'model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.weight', 'model.1.submodule.1.submodule.1.submodule.1.submodule.2.conv.bias', 'model.1.submodule.1.submodule.1.submodule.1.submodule.2.adn.A.weight', 'model.1.submodule.1.submodule.1.submodule.2.conv.weight', 'model.1.submodule.1.submodule.1.submodule.2.conv.bias', 'model.1.submodule.1.submodule.1.submodule.2.adn.A.weight', 'model.1.submodule.1.submodule.2.conv.weight', 'model.1.submodule.1.submodule.2.conv.bias', 'model.1.submodule.1.submodule.2.adn.A.weight', 'model.1.submodule.2.conv.weight', 'model.1.submodule.2.conv.bias', 'model.1.submodule.2.adn.A.weight', 'model.2.conv.weight', 'model.2.conv.bias'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-17 15:52:29.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1moutput shape: torch.Size([1, 145, 96, 96, 96])\u001b[0m\n",
      "\u001b[32m2025-01-17 15:52:29.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mmissing_keys: []\u001b[0m\n",
      "\u001b[32m2025-01-17 15:52:29.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1munexpected_keys: ['loss.dice.class_weight']\u001b[0m\n",
      "\u001b[32m2025-01-17 15:52:29.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mLoaded pretrained anatomy model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "anatomy_ckpt_path = '/Users/keyi/Desktop/epoch=399-step=30460.ckpt'\n",
    "if not anatomy_ckpt_path:\n",
    "    raise ValueError(\"Pretrained anatomy model path not specified in config\")\n",
    "    \n",
    "logger.info(f\"Loading pretrained anatomy model from {anatomy_ckpt_path}\")\n",
    "ckpt = torch.load(anatomy_ckpt_path, map_location='cpu')\n",
    "\n",
    "print(f\"checkpoint keys: {ckpt['state_dict'].keys()}\")\n",
    "print(f\"model keys: {m.model.state_dict().keys()}\")\n",
    "if 'state_dict' in ckpt:\n",
    "    anatomy_state_dict = {k.replace('model.model.', 'model.'): v for k, v in ckpt['state_dict'].items()}\n",
    "else:\n",
    "    anatomy_state_dict = ckpt\n",
    "    \n",
    "missing_keys, unexpected_keys = m.model.load_state_dict(\n",
    "    anatomy_state_dict, strict=False\n",
    ")\n",
    "a = torch.randn(1,1,96,96,96)\n",
    "o = m.model(a)\n",
    "logger.info(f\"output shape: {o.shape}\")\n",
    "logger.info(f\"missing_keys: {missing_keys}\")\n",
    "logger.info(f\"unexpected_keys: {unexpected_keys}\")\n",
    "logger.info(\"Loaded pretrained anatomy model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "feature_fused_channels = [\"320_conv1\", \"320_conv2\"]\n",
    "channel = 320\n",
    "if channel in feature_fused_channels:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape in bottleneck: torch.Size([1, 320, 6, 6, 6])\n",
      "input_data shape: torch.Size([1, 1, 96, 96, 96])\n",
      "output shape: torch.Size([1, 4, 145, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_data = torch.randn(1, 1, 96, 96, 96)  # B, C, H, W, D\n",
    "\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"output shape in bottleneck: {output.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "bottleneck = m.model.bottleneck.conv1.conv\n",
    "hook = bottleneck.register_forward_hook(hook_fn)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = m.model(input_data)\n",
    "    \n",
    "\n",
    "hook.remove()\n",
    "\n",
    "\n",
    "print(f\"input_data shape: {input_data.shape}\")\n",
    "print(f\"output shape: {output.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvhci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
